{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9a1991-ba0f-4cf3-a97a-a7c374f373fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6771282-803d-49e4-a8ba-b2a97d07f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0142b01f2645429e8650f79f738b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map = \"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02aa7519-8bea-4f11-a495-668abac458f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and select the test set \n",
    "dataset = load_dataset('openai/gsm8k', 'main')\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# function to extract the answer from the golden answers\n",
    "def estrai_numero(input_string):\n",
    "    # Usa una regex per trovare il numero dopo ###\n",
    "    match = re.search(r'###\\s*(\\d+)', input_string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# extract the correct answers\n",
    "correct_answers = []\n",
    "for i in range(len(test_dataset)):\n",
    "  correct_answers.append(estrai_numero(test_dataset['answer'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1351f006-bbbb-4b4f-8eba-5ef4eff6b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loader = HuggingFaceDatasetLoader('saracandu/references-gsm8k', 'docs')\n",
    "documents = loader.load()\n",
    "\n",
    "# create an instance of the RecursiveCharacterTextSplitter class with specific parameters\n",
    "# (it splits text into chunks of 50 characters each with a 20-character overlap)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\n",
    "\n",
    "# 'documents' holds the text you want to split, split the text into documents using the text splitter\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# choose an embedding method\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# embed the documents 'docs' into vectors using the embedding method specified by 'embedding'\n",
    "# the result is stored in a FAISS index:\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_kwargs={'k': 5,}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab8f721-6f7d-486e-ad15-a5bc6edc862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_page_content(documents):\n",
    "    \"\"\"\n",
    "    Formats the list of retrieved documents such that 'page_content', 'Documents', 'metadata' \n",
    "    words are removed and just the true content is kept.\n",
    "    \"\"\"\n",
    "    formatted_output = \"\"\n",
    "    for i, doc in enumerate(documents, start=1):\n",
    "        content = doc.page_content.strip(\" \")\n",
    "        formatted_output += f\"[{i}]: {content}\\n\"\n",
    "    return formatted_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006abbc0-b921-48b0-aba5-b3497cad500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_cot_RAG_1s(question, context):\n",
    "    content = f\"\"\"\n",
    "    Question: \"{question}\";\n",
    "    Context: \"{context}\". Let's think step by step.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a helpful AI assistant asked to solve mathematical problems using similar problems already solved as context. \n",
    "        Output your numerical answer only after these symbols ###.        \n",
    "        Question: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\n",
    "        Context: Anna cooks a 30-muffin set to 2 different friends three times a week. How many muffins does she cook in a year? She cooks each friend 30*2=<<30*2=60>>60 muffins a week So she cooks 60*2=<<60*2=120>>120 muffins every week That means she cooks 120*52=<<120*52=6240>>6240 muffins a year.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        Assistant: #### 6240\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b9eec2-de80-41d7-ad35-26d034c38859",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_cot_RAG_1s = []\n",
    "\n",
    "for i in range(5):\n",
    "    relevant_passages = format_page_content(retriever.invoke(test_dataset['question'][i]))\n",
    "    messages = create_message_cot_RAG_1s(test_dataset['question'][i], relevant_passages)\n",
    "    output = pipe(messages, **generation_args)\n",
    "    answers_cot_RAG_1s.append(estrai_numero(output[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba21509c-7bfe-4739-bcfe-3a8a07e6e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40', '160', '60', '180', '120']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_cot_RAG_1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ced8c0-6f76-4c6d-bbf9-b72be6fe094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries = train_dataset['question']\n",
    "queries = test_dataset['queries']\n",
    "\n",
    "df = {\n",
    "    'query': queries,\n",
    "    'correct': correct_answers,\n",
    "    'answer': answers_cot_0s\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

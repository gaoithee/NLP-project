{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f5e571-161d-4644-b233-d8e91e47b7ca",
   "metadata": {},
   "source": [
    "Prova a vedere se riesci a replicare questo benchmark: https://klu.ai/glossary/GSM8K-eval\n",
    "\n",
    "Risorse per il RAG: https://www.mathlearningcenter.org/educators/free-resources/lessons-publications/practice-books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3e17047-5f84-452e-af88-a34e10d20ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93124d9f-9829-4a3a-ad34-3e37327451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca5bcd-ae36-4704-b39e-cfbe796284fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# upload the model and construct the generation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cef8c-f332-4b70-9e00-ad5417997467",
   "metadata": {},
   "source": [
    "nel paper originale mostrano che al crescere del numero dei parametri del modello la capacità di reasoning migliora -> vedere come va per gli altri phi?\n",
    "o magari spostarsi su gemma-2b e gemma-7b... capire se ci stanno su ORFEO però"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c97e3ac4-a230-4361-9c79-f5e0c4e43143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbcd96b7f934ca68d3af9d09c5d3ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(0)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map = \"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35d0ebc0-6c07-4eff-b9e5-92f55fb3b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce31fb-fb77-493f-8f7e-a3184e854d6c",
   "metadata": {},
   "source": [
    "# upload the dataset: `openai/gsm8k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7372b4be-d488-4ee1-9d75-56bd0f1b0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('openai/gsm8k', 'main')\n",
    "train_dataset = dataset['train']\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28f4053b-9134-4d88-b37f-49afd177e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60c71a-e6d7-4630-80e4-ed49e4c60edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# extract the correct answer from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a1d955e-22c5-4ad1-a7a7-952061557f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def estrai_numero(input_string):\n",
    "    # Usa una regex per trovare il numero dopo ###\n",
    "    match = re.search(r'###\\s*(\\d+)', input_string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77aca7c2-a931-4a3c-aa4a-cc315c596115",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_answers = []\n",
    "\n",
    "for i in range(N_rows):\n",
    "  correct_answers.append(estrai_numero(train_dataset['answer'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2f2e0d6-2189-4b07-8f52-ff2929d8c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72', '10', '5', '42', '624']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef67215-bccf-4e50-9266-7afb31843b5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# baseline: zero-shot question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c779ad74-0410-4dd3-9413-d424497f5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message3(question):\n",
    "    content = f\"\"\"\n",
    "    Question: \"{question}\".\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a helpful AI assistant asked to solve mathematical problems. Output your numerical answer only after these symbols ###.\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb989351-559a-45cc-8b12-b7da3b368b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/scandu00/nlp-env/lib64/python3.9/site-packages/transformers/pipelines/base.py:1167: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "answers_baseline = []\n",
    "for i in range(N_rows):\n",
    "  messages = create_message3(train_dataset['question'][i])\n",
    "  output = pipe(messages, **generation_args)\n",
    "  answers_baseline.append(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1100586-1552-4bfb-8b4b-30684a2e13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_baseline_def = []\n",
    "for i in range(N_rows):\n",
    "    answers_baseline_def.append(estrai_numero(answers_baseline[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "003cdd26-83c0-47a6-a12f-f75b21073213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72', '10', None, None, '624']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_baseline_def[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87f98f-92c2-4efa-899b-ab68d161855d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# baseline #2: one-shot question (just the answer, not CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea084854-37c3-431f-bc41-799d7de17a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message2(question):\n",
    "    content = f\"\"\"\n",
    "    Question: \"{question}\".\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a helpful AI assistant asked to solve mathematical problems. Output your numerical answer only after these symbols ###.\n",
    "        Question: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\n",
    "        \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        Assistant: ### 624\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971990e-e087-4148-b445-722bac6525a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_baseline2 = []\n",
    "for i in range(N_rows):\n",
    "  messages = create_message2(train_dataset['question'][i])\n",
    "  output = pipe(messages, **generation_args)\n",
    "  answers_baseline2.append(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f43263-7f7d-4edf-a2b3-f0741eb82188",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_baseline2_def = []\n",
    "for i in range(N_rows):\n",
    "    answers_baseline2_def.append(estrai_numero(answers_baseline2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b0dee2a-5e85-4d03-aba8-6bd390019592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72', '10', '25', '36', '624']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_baseline2_def[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c8cb4-6fa5-4872-8a17-4a30bf7903b0",
   "metadata": {},
   "source": [
    "# one-shot CoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c594867-c4f9-40c2-8f09-007b9b441511",
   "metadata": {},
   "source": [
    "says who? gli autori: https://arxiv.org/pdf/2201.11903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72a44b14-2068-4f1d-989f-2a025580c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message(question):\n",
    "    content = f\"\"\"\n",
    "    Question: \"{question}\".\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a helpful AI assistant asked to solve mathematical problems.\n",
    "        Question: James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?\n",
    "        \"\"\"},\n",
    "        {\"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        Assistant: He writes each friend 3*2=6 pages a week So he writes 6*2=12 pages every week That means he writes 12*52=624 pages a year. ### 624\n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": content},\n",
    "    ]\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f9619-2c1b-4056-bc29-808e1108ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_cot = []\n",
    "for i in range(N_rows):\n",
    "  messages = create_message(train_dataset['question'][i])\n",
    "  output = pipe(messages, **generation_args)\n",
    "  answers_cot.append(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14084495-8470-4a26-a622-b8eb19ca2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_cot_def = []\n",
    "for i in range(N_rows):\n",
    "    answers_cot_def.append(estrai_numero(answers_cot[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087209e-21ff-4f14-a912-ebd9c521bc3f",
   "metadata": {},
   "source": [
    "# creazione di un dataset con tutte le nuove risposte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aeed8b-b340-49a6-a0db-b440103f4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = {\n",
    "    'domanda': train_dataset['question'][:N_rows],\n",
    "    'corretta': correct_answers,\n",
    "    'baseline 1': answers_baseline_def,\n",
    "    'baseline 2': answers_baseline2_def,\n",
    "    'one-shot CoT': answers_cot_def\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7913fc-616b-489e-9d34-11ab0e65423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dati)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd686778-3d06-4846-8857-e9ce38386942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('first-500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db1d5e-52b2-479c-a62b-63d87268d7e0",
   "metadata": {},
   "source": [
    "# valutazione delle performance (da sistemare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15f91d7c-e5fe-4a7d-8529-746c67d0b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sum = 0\n",
    "\n",
    "for i in range(N_rows):\n",
    "    if correct_answers[i] == answers_cot_def[i]:\n",
    "        my_sum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdc1485b-2d41-4c19-94ec-5d45d32f5a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3b35f40-ee64-4d04-a1cb-e6d2bcea7938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a24a5ecb-2faa-4508-ad22-acc9c120e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e666ff-4bd5-4ae6-a3c5-e4e632175625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed316d-0989-4a5c-a69a-8c67446f054e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
